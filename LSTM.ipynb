{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IafQUtjKEVEb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "# import keras\n",
        "# from keras.layers import *\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFX3Ry5VHShU",
        "outputId": "d0f95aec-43a3-4842-e63e-de67a6cdf60e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-94c0hcEVEi",
        "outputId": "841e9b2b-c0eb-45f7-f28c-1ec6a0b3e986"
      },
      "source": [
        "blog_posts_data_dir = \"/content/drive/MyDrive/datasets/\"\n",
        "blog_posts_data_dir = \"/content/drive/MyDrive/datasets/BT-AP-19 Corpus/all/\"\n",
        "train_file_name = \"train.json\"\n",
        "test_file_name = \"test.json\"\n",
        "\n",
        "# Load data\n",
        "with open(blog_posts_data_dir + train_file_name) as r:\n",
        "    training_set = json.load(r)\n",
        "training_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': '50', 'gender': 'female', 'post': 'Umar Murtaza: Head of SM Operation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7nvAqzREVEm"
      },
      "source": [
        "EXAMINE = 21\n",
        "SEED = 22\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt0bfTeSEVEn"
      },
      "source": [
        "def get_gender_as_num(gender):\n",
        "    if gender == \"male\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y724yobEVEo"
      },
      "source": [
        "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
        "    if age < 18:\n",
        "        # 13 - 17\n",
        "        return [1, 0, 0, 0]\n",
        "    elif age < 28:\n",
        "        # 23 - 27\n",
        "        return [0, 1, 0, 0]\n",
        "    elif age < 49:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 1, 0]\n",
        "    else:\n",
        "        return [0, 0, 0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCtPkaL2LVsv"
      },
      "source": [
        "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
        "    age = int(age)\n",
        "    if age == 18:\n",
        "        # 13 - 17\n",
        "        return [1, 0, 0, 0]\n",
        "    elif age == 25:\n",
        "        # 23 - 27\n",
        "        return [0, 1, 0, 0]\n",
        "    elif age == 35:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 1, 0]\n",
        "    elif age == 50:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 0, 1]\n",
        "    else:\n",
        "        return [0, 0, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt9ltT5LEVEq",
        "outputId": "a7423006-d117-4704-90a9-2e1e9c620a9b"
      },
      "source": [
        "raw_posts = [instance[\"post\"] for instance in training_set]\n",
        "len(raw_posts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4fLmlqPEVEu"
      },
      "source": [
        "# TODO add stop word filtering \n",
        "median_words_per_sample = np.median([len(instance[\"post\"]) for instance in training_set])\n",
        "\n",
        "# Map each word to a unique int value\n",
        "MAX_WORD_COUNT = 20000\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words = MAX_WORD_COUNT)\n",
        "posts = [instance[\"post\"] for instance in training_set]\n",
        "tokenizer.fit_on_texts(posts)\n",
        "word_index = dict(list(tokenizer.word_index.items())[:20000])\n",
        "sequences = tokenizer.texts_to_sequences(posts)\n",
        "median_words_per_tokenized_sample = np.median([len(post) for post in sequences])\n",
        "data = keras.preprocessing.sequence.pad_sequences(sequences, maxlen = int(median_words_per_tokenized_sample),\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(training_set):\n",
        "    instance[\"post\"] = data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0jroo6LEVEw"
      },
      "source": [
        "EMBEDDING_DIM = 50\n",
        "\n",
        "glove_path = \"/content/drive/MyDrive/datasets/\"\n",
        "glove_dict = {}\n",
        "with open(glove_path + \"glove.6B.50d.txt\") as f:\n",
        "    for line in f:\n",
        "        line_values = line.split(\" \")\n",
        "        word = line_values[0]\n",
        "        embedding_coefficients = np.asarray(line_values[1 : ], dtype = \"float32\")\n",
        "        glove_dict[word] = embedding_coefficients\n",
        "\n",
        "glove_weights = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    glove_vector = glove_dict.get(word)\n",
        "    if glove_vector is not None:\n",
        "        glove_weights[i] = glove_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPRAXBykEVEy"
      },
      "source": [
        "model_1 = keras.Sequential()\n",
        "model_1.add(keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [glove_weights],\n",
        "                                    input_length = int(median_words_per_tokenized_sample), trainable = True))\n",
        "\n",
        "\n",
        "# Add hidden layers \n",
        "for i in range(0, 3):\n",
        "    # Add a bidirectional lstm layer\n",
        "    model_1.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.2)))\n",
        "    # Add a dropout layer after each lstm layer\n",
        "    model_1.add(Dropout(0.5))\n",
        "model_1.add(Bidirectional(LSTM(32, recurrent_dropout=0.2)))\n",
        "model_1.add(Dropout(0.5))\n",
        "# Add the fully connected layer with 256 nurons and relu activation\n",
        "model_1.add(Dense(256, activation='relu'))\n",
        "# Add the output layer with softmax activation since we have 2 classes\n",
        "model_1.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqgAnFcvEVE1",
        "outputId": "16033d7c-d212-4bf4-c2b0-e3e8e06b24c3"
      },
      "source": [
        "model_1.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 9, 50)             1000050   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 9, 64)             21248     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 9, 64)             24832     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 9, 64)             24832     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 1,113,205\n",
            "Trainable params: 1,113,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSDJtj7mNPTT"
      },
      "source": [
        "def create_model(type=True):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [glove_weights],\n",
        "                                        input_length = int(median_words_per_tokenized_sample), trainable = True))\n",
        "\n",
        "\n",
        "    # Add hidden layers \n",
        "    for i in range(0, 3):\n",
        "        # Add a bidirectional lstm layer\n",
        "        model.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.2)))\n",
        "        # Add a dropout layer after each lstm layer\n",
        "        model.add(Dropout(0.5))\n",
        "    model.add(Bidirectional(LSTM(32, recurrent_dropout=0.2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    # Add the fully connected layer with 256 nurons and relu activation\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    # Add the output layer with softmax activation since we have 2 classes\n",
        "    if type: \n",
        "        model.add(Dense(4, activation='softmax')) \n",
        "    else:\n",
        "        model.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7viY3ldINYmm",
        "outputId": "bdfb344c-b6f3-4dff-e3fd-d100c421ef15"
      },
      "source": [
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.102.178.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.102.178.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 9, 50)             1000050   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 9, 64)             21248     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 9, 64)             24832     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 9, 64)             24832     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 1,113,462\n",
            "Trainable params: 1,113,462\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_JWyJjSEVE3"
      },
      "source": [
        "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
        "ages_train = np.array([instance[\"age\"] for instance in training_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVoH05fdEVE4",
        "outputId": "367bdb31-a8c3-43f7-c7b4-274867558e5f"
      },
      "source": [
        "history_1 = model.fit(posts_train, ages_train, epochs = 10, batch_size = 50, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "539/539 [==============================] - 30s 41ms/step - loss: 0.7814 - accuracy: 0.6745 - val_loss: 1.2676 - val_accuracy: 0.5059\n",
            "Epoch 2/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.6790 - accuracy: 0.7202 - val_loss: 1.3191 - val_accuracy: 0.5100\n",
            "Epoch 3/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.6151 - accuracy: 0.7464 - val_loss: 1.3314 - val_accuracy: 0.5043\n",
            "Epoch 4/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.5763 - accuracy: 0.7619 - val_loss: 1.5357 - val_accuracy: 0.5165\n",
            "Epoch 5/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.5370 - accuracy: 0.7738 - val_loss: 1.5966 - val_accuracy: 0.5123\n",
            "Epoch 6/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.5149 - accuracy: 0.7837 - val_loss: 1.6219 - val_accuracy: 0.5062\n",
            "Epoch 7/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.4838 - accuracy: 0.7954 - val_loss: 1.7493 - val_accuracy: 0.5131\n",
            "Epoch 8/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.4622 - accuracy: 0.8050 - val_loss: 2.0097 - val_accuracy: 0.5107\n",
            "Epoch 9/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.4497 - accuracy: 0.8086 - val_loss: 1.9767 - val_accuracy: 0.5062\n",
            "Epoch 10/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.4356 - accuracy: 0.8154 - val_loss: 1.9171 - val_accuracy: 0.5110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVeI5I_aKgdF"
      },
      "source": [
        "# Load data\n",
        "with open(blog_posts_data_dir + test_file_name) as r:\n",
        "    test_set = json.load(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shlV1VXGRUgU"
      },
      "source": [
        "test_posts = [instance[\"post\"] for instance in test_set]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_posts)\n",
        "test_post_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = int(median_words_per_tokenized_sample),\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(test_set):\n",
        "    instance[\"post\"] = test_post_data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYX4pLZLQ4M9"
      },
      "source": [
        "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
        "ages_test = np.array([instance[\"age\"] for instance in test_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaEiLbLhQ8J1",
        "outputId": "e27a815f-7bbf-4302-abcc-d6966d5cd5af"
      },
      "source": [
        "model.evaluate(posts_test, ages_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263/263 [==============================] - 5s 17ms/step - loss: 1.8763 - accuracy: 0.4872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8762813806533813, 0.4871581494808197]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6Woi_R0RDRc",
        "outputId": "791712f2-cd73-4b1b-8aa3-e2a7c1417fd6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(posts_test)\n",
        "print(classification_report(np.argmax(ages_test, axis=1), np.argmax(pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.66      0.59      2698\n",
            "           1       0.52      0.40      0.45      2647\n",
            "           2       0.45      0.43      0.44      2309\n",
            "           3       0.33      0.36      0.34       756\n",
            "\n",
            "    accuracy                           0.49      8410\n",
            "   macro avg       0.46      0.46      0.46      8410\n",
            "weighted avg       0.49      0.49      0.48      8410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08IqqR9w4NLU"
      },
      "source": [
        "## Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs4FTj4UEbgm"
      },
      "source": [
        "def create_model_gender():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [glove_weights],\n",
        "                                        input_length = int(median_words_per_tokenized_sample), trainable = True))\n",
        "\n",
        "\n",
        "    # Add hidden layers \n",
        "    for i in range(0, 3):\n",
        "        # Add a bidirectional lstm layer\n",
        "        model.add(Bidirectional(LSTM(64, return_sequences=True, recurrent_dropout=0.2)))\n",
        "        # Add a dropout layer after each lstm layer\n",
        "        model.add(Dropout(0.5))\n",
        "    model.add(Bidirectional(LSTM(64, recurrent_dropout=0.2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    # Add the fully connected layer with 256 nurons and relu activation\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    # Add the output layer with softmax activation since we have 2 classes\n",
        "    model.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdbEip8M4MVW"
      },
      "source": [
        "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
        "genders_train = np.array([instance[\"gender\"] for instance in training_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcwC7N8N4asE",
        "outputId": "64dbda0c-d20f-48ea-8c8f-ee6c015a1bea"
      },
      "source": [
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "    model_gender = create_model_gender()\n",
        "    model_gender.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "    model_gender.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.102.178.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.102.178.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.102.178.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.102.178.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 9, 50)             1000050   \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 9, 128)            58880     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 9, 128)            98816     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 9, 128)            98816     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,356,679\n",
            "Trainable params: 1,356,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7_dRy534gXG",
        "outputId": "23b0c522-8514-4cb1-a4e8-36c1a9c84dd7"
      },
      "source": [
        "history_gender = model_gender.fit(posts_train, genders_train, epochs = 10, batch_size = 50, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "539/539 [==============================] - 52s 46ms/step - loss: 0.6011 - accuracy: 0.6922 - val_loss: 0.5499 - val_accuracy: 0.7250\n",
            "Epoch 2/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.5154 - accuracy: 0.7541 - val_loss: 0.5169 - val_accuracy: 0.7493\n",
            "Epoch 3/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.4289 - accuracy: 0.8043 - val_loss: 0.5173 - val_accuracy: 0.7516\n",
            "Epoch 4/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.3399 - accuracy: 0.8481 - val_loss: 0.5481 - val_accuracy: 0.7632\n",
            "Epoch 5/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.2822 - accuracy: 0.8750 - val_loss: 0.5361 - val_accuracy: 0.7579\n",
            "Epoch 6/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.2510 - accuracy: 0.8919 - val_loss: 0.6584 - val_accuracy: 0.7567\n",
            "Epoch 7/10\n",
            "539/539 [==============================] - 13s 24ms/step - loss: 0.2175 - accuracy: 0.9023 - val_loss: 0.7048 - val_accuracy: 0.7613\n",
            "Epoch 8/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.1961 - accuracy: 0.9136 - val_loss: 0.8324 - val_accuracy: 0.7585\n",
            "Epoch 9/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.1737 - accuracy: 0.9210 - val_loss: 0.8681 - val_accuracy: 0.7540\n",
            "Epoch 10/10\n",
            "539/539 [==============================] - 13s 25ms/step - loss: 0.1692 - accuracy: 0.9243 - val_loss: 1.0200 - val_accuracy: 0.7478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNYGDVirHKW9"
      },
      "source": [
        "# Load data\n",
        "with open(blog_posts_data_dir + test_file_name) as r:\n",
        "    test_set = json.load(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x__VE7OVHPSq"
      },
      "source": [
        "test_posts = [instance[\"post\"] for instance in test_set]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_posts)\n",
        "test_post_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = int(median_words_per_tokenized_sample),\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(test_set):\n",
        "    instance[\"post\"] = test_post_data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNRDY_r8HQ-Z"
      },
      "source": [
        "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
        "genders_test = np.array([instance[\"gender\"] for instance in test_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qveBZn0AHUiA",
        "outputId": "1dc5353c-4bcc-41c7-b46a-e8a9369e51dd"
      },
      "source": [
        "model_gender.evaluate(posts_test, genders_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263/263 [==============================] - 5s 18ms/step - loss: 0.9911 - accuracy: 0.7512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9910658001899719, 0.7512485384941101]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wieEDCJ0HYa4"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6GLSELfHaHR"
      },
      "source": [
        "pred = model_gender.predict(posts_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd2zpzWWHcCA",
        "outputId": "d582ed66-1e8e-49bb-d2c3-018b8e5e3131"
      },
      "source": [
        "print(classification_report(genders_test, (pred > 0.5).astype(int)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.50      0.55      2565\n",
            "           1       0.80      0.86      0.83      5845\n",
            "\n",
            "    accuracy                           0.75      8410\n",
            "   macro avg       0.71      0.68      0.69      8410\n",
            "weighted avg       0.74      0.75      0.74      8410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}