{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-Char-level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D12Ju3uzIbKV"
      },
      "source": [
        "https://towardsdatascience.com/character-level-cnn-with-keras-50391c3adf33\n",
        "https://www.kaggle.com/kmader/character-level-cnn-classification-with-dilations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbeWji5WmAcm"
      },
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "# import keras\n",
        "# from keras.layers import *\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "# import tensorflow_text as text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VubVoODmmmSx",
        "outputId": "9adc182d-34cb-42c2-beca-9622e6be9be7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd8OTy3_moKn",
        "outputId": "61a7d6aa-efe9-4a2f-89db-813eff8cb706"
      },
      "source": [
        "import json\n",
        "blog_posts_data_dir = \"/content/drive/MyDrive/datasets/BT-AP-19 Corpus/all/\"\n",
        "# blog_posts_data_dir = \"/content/drive/MyDrive/datasets/\"\n",
        "train_file_name = \"train.json\"\n",
        "test_file_name = \"test.json\"\n",
        "\n",
        "# Load data\n",
        "with open(blog_posts_data_dir + train_file_name) as r:\n",
        "    training_set = json.load(r)\n",
        "training_set = training_set[:400000]\n",
        "training_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': '50', 'gender': 'female', 'post': 'Umar Murtaza: Head of SM Operation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR6yEn_vmwtS"
      },
      "source": [
        "def get_gender_as_num(gender):\n",
        "    if gender == \"male\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5clEfdt2nNin"
      },
      "source": [
        "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
        "    if age < 18:\n",
        "        # 13 - 17\n",
        "        return [1, 0, 0]\n",
        "    elif age < 28:\n",
        "        # 23 - 27\n",
        "        return [0, 1, 0]\n",
        "    elif age < 49:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 1]\n",
        "    else:\n",
        "        return [0, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5zyUStJ92-l"
      },
      "source": [
        "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
        "    age = int(age)\n",
        "    if age == 18:\n",
        "        # 13 - 17\n",
        "        return [1, 0, 0, 0]\n",
        "    elif age == 25:\n",
        "        # 23 - 27\n",
        "        return [0, 1, 0, 0]\n",
        "    elif age == 35:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 1, 0]\n",
        "    elif age == 50:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 0, 1]\n",
        "    else:\n",
        "        return [0, 0, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8Uf-d3ynchu",
        "outputId": "3870bef9-5c08-4260-d3f9-af16b8ac9cbf"
      },
      "source": [
        "posts = [instance[\"post\"] for instance in training_set]\n",
        "len(posts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZf7xnPWnzO-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ByFLEAQn9vu"
      },
      "source": [
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tk.fit_on_texts(posts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8HM_2cnokfX",
        "outputId": "0f1221e8-ceed-4223-c854-7e103da231e5"
      },
      "source": [
        "len(tk.word_index)\n",
        "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
        "char_dict = {}\n",
        "for i, char in enumerate(alphabet):\n",
        "    char_dict[char] = i + 1\n",
        "\n",
        "# Use char_dict to replace the tk.word_index\n",
        "tk.word_index = char_dict.copy()\n",
        "# Add 'UNK' to the vocabulary\n",
        "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1\n",
        "len(tk.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbw-O2XkoKHi",
        "outputId": "959eec86-3ba8-47dc-ba32-b5d2cfef41c3"
      },
      "source": [
        "sequences = tk.texts_to_sequences(posts)\n",
        "median_words_per_tokenized_sample = np.median([len(post) for post in sequences])\n",
        "median_words_per_tokenized_sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcRdmWK2pdXk"
      },
      "source": [
        "data = keras.preprocessing.sequence.pad_sequences(sequences, maxlen = int(median_words_per_tokenized_sample),\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(training_set):\n",
        "    instance[\"post\"] = data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otuIfvinp5Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7c71d7-b0f8-4c13-c024-19316dc0e9b8"
      },
      "source": [
        "training_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': [0, 0, 0, 1],\n",
              " 'gender': 1,\n",
              " 'post': array([21, 13,  1, 18, 69, 13, 21, 18, 20,  1, 26,  1, 42, 69,  8,  5,  1,\n",
              "         4, 69, 15,  6, 69, 19, 13, 69, 15, 16,  5, 18,  1, 20,  9, 15, 14,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFO9iEWLqFW8"
      },
      "source": [
        "input_size = int(median_words_per_tokenized_sample)\n",
        "vocab_size = len(tk.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NtJfYn7qdib"
      },
      "source": [
        "embedding_size = 100#len(tk.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuoY3I-Gqf58"
      },
      "source": [
        "conv_layers = [[256, 7, 3],\n",
        "            #    [256, 7, 3],\n",
        "            #    [256, 3, -1],\n",
        "            #    [256, 3, -1],\n",
        "            #    [256, 3, -1],\n",
        "               [256, 3, 3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JuxJcOrqhTr"
      },
      "source": [
        "fully_connected_layers = [1024, 1024]\n",
        "num_of_classes = 4\n",
        "dropout_p = 0.5\n",
        "optimizer = 'adam'\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ac1UYJyqnmL",
        "outputId": "6ef5314d-40c8-49b9-d4ae-423daada96d1"
      },
      "source": [
        "# Embedding weights\n",
        "embedding_weights = []  # (70, 69)\n",
        "embedding_weights.append(np.zeros(vocab_size))  # (0, 69)\n",
        "\n",
        "for char, i in tk.word_index.items():  # from index 1 to 69\n",
        "    onehot = np.zeros(vocab_size)\n",
        "    onehot[i - 1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "\n",
        "embedding_weights = np.array(embedding_weights)\n",
        "embedding_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 69)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79DPVLtBqpKT",
        "outputId": "4b2f7758-0849-4ee0-d16e-1c88b1ded3a8"
      },
      "source": [
        "embedding_layer = Embedding(vocab_size + 1,\n",
        "                            embedding_size,\n",
        "                            input_length=input_size)\n",
        "\n",
        "inputs = Input(shape=(input_size,), name='input', dtype='int64')  # shape=(?, 1014)\n",
        "x = embedding_layer(inputs)\n",
        "# Conv\n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    x = Conv1D(filter_num, filter_size)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if pooling_size != -1:\n",
        "        x = MaxPooling1D(pool_size=pooling_size)(x)  # Final shape=(None, 34, 256)\n",
        "x = Flatten()(x)  # (None, 8704)\n",
        "# Fully connected layers\n",
        "for dense_size in fully_connected_layers:\n",
        "    x = Dense(dense_size, activation='relu')(x)  # dense_size == 1024\n",
        "    x = Dropout(dropout_p)(x)\n",
        "# Output Layer\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "# Build model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])  # Adam, categorical_crossentropy\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 55)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 55, 100)           7000      \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 49, 256)           179456    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 49, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 14, 256)           196864    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 14, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 2,486,620\n",
            "Trainable params: 2,486,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ou4fg0eq6Cr"
      },
      "source": [
        "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
        "ages_train = np.array([instance[\"age\"] for instance in training_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJyR8ItOsfUZ",
        "outputId": "3ae0b47a-7289-44b4-c2b5-85f01b14243e"
      },
      "source": [
        "history_1 = model.fit(posts_train, ages_train, epochs = 10, batch_size = 500, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "54/54 [==============================] - 33s 47ms/step - loss: 1.3131 - accuracy: 0.3229 - val_loss: 1.2509 - val_accuracy: 0.3934\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 1.2433 - accuracy: 0.3970 - val_loss: 1.2207 - val_accuracy: 0.4203\n",
            "Epoch 3/10\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 1.1865 - accuracy: 0.4350 - val_loss: 1.1887 - val_accuracy: 0.4410\n",
            "Epoch 4/10\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 1.1114 - accuracy: 0.4890 - val_loss: 1.1948 - val_accuracy: 0.4328\n",
            "Epoch 5/10\n",
            "54/54 [==============================] - 2s 36ms/step - loss: 1.0232 - accuracy: 0.5456 - val_loss: 1.3044 - val_accuracy: 0.4348\n",
            "Epoch 6/10\n",
            "54/54 [==============================] - 2s 36ms/step - loss: 0.9031 - accuracy: 0.6040 - val_loss: 1.2768 - val_accuracy: 0.4431\n",
            "Epoch 7/10\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 0.7426 - accuracy: 0.6831 - val_loss: 1.4019 - val_accuracy: 0.4392\n",
            "Epoch 8/10\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 0.6466 - accuracy: 0.7300 - val_loss: 1.5220 - val_accuracy: 0.4383\n",
            "Epoch 9/10\n",
            "54/54 [==============================] - 2s 36ms/step - loss: 0.5174 - accuracy: 0.7901 - val_loss: 1.6799 - val_accuracy: 0.4350\n",
            "Epoch 10/10\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 0.4323 - accuracy: 0.8276 - val_loss: 1.9119 - val_accuracy: 0.4416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKSS0PXm2PTr",
        "outputId": "21a5fffe-1538-435c-d4c4-3c1f33b07e52"
      },
      "source": [
        "def build_model(conv_layers = 2, \n",
        "                dilation_rates = [0, 2, 4, 8, 16], \n",
        "                embed_size = 256):\n",
        "    inp = Input(shape=(None, ))\n",
        "    x = Embedding(input_dim = len(tk.word_counts)+1, \n",
        "                  output_dim = embed_size)(inp)\n",
        "    prefilt_x = Dropout(0.25)(x)\n",
        "    out_conv = []\n",
        "    # dilation rate lets us use ngrams and skip grams to process \n",
        "    for dilation_rate in dilation_rates:\n",
        "        x = prefilt_x\n",
        "        for i in range(2):\n",
        "            if dilation_rate>0:\n",
        "                x = Conv1D(16*2**(i), \n",
        "                           kernel_size = 3, \n",
        "                           dilation_rate = dilation_rate,\n",
        "                          activation = 'relu',\n",
        "                          name = 'ngram_{}_cnn_{}'.format(dilation_rate, i)\n",
        "                          )(x)\n",
        "            else:\n",
        "                x = Conv1D(16*2**(i), \n",
        "                           kernel_size = 1,\n",
        "                          activation = 'relu',\n",
        "                          name = 'word_fcl_{}'.format(i))(x)\n",
        "        out_conv += [Dropout(0.5)(GlobalMaxPool1D()(x))]\n",
        "    x = concatenate(out_conv, axis = -1)    \n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(num_of_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model2 = build_model(dilation_rates = [0, 2, 4, 8])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, None, 256)    144384      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, None, 256)    0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "word_fcl_0 (Conv1D)             (None, None, 16)     4112        dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_2_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_4_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_8_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "word_fcl_1 (Conv1D)             (None, None, 32)     544         word_fcl_0[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_2_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_2_cnn_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "ngram_4_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_4_cnn_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "ngram_8_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_8_cnn_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_25 (Global (None, 32)           0           word_fcl_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_26 (Global (None, 32)           0           ngram_2_cnn_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_27 (Global (None, 32)           0           ngram_4_cnn_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_28 (Global (None, 32)           0           ngram_8_cnn_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 32)           0           global_max_pooling1d_25[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 32)           0           global_max_pooling1d_26[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 32)           0           global_max_pooling1d_27[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 32)           0           global_max_pooling1d_28[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 128)          0           dropout_48[0][0]                 \n",
            "                                                                 dropout_49[0][0]                 \n",
            "                                                                 dropout_50[0][0]                 \n",
            "                                                                 dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 64)           8256        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 64)           0           dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 32)           2080        dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 32)           0           dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 4)            132         dropout_53[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 201,124\n",
            "Trainable params: 201,124\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR9Imsj53Jxh",
        "outputId": "2084ee6e-1831-4458-9af8-1959fec886b9"
      },
      "source": [
        "history_1 = model2.fit(posts_train, ages_train, epochs = 20, batch_size = 500, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "54/54 [==============================] - 5s 63ms/step - loss: 1.3448 - accuracy: 0.2828 - val_loss: 1.2906 - val_accuracy: 0.3401\n",
            "Epoch 2/20\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 1.3038 - accuracy: 0.3263 - val_loss: 1.2802 - val_accuracy: 0.3830\n",
            "Epoch 3/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.2908 - accuracy: 0.3587 - val_loss: 1.2556 - val_accuracy: 0.4058\n",
            "Epoch 4/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.2678 - accuracy: 0.3787 - val_loss: 1.2422 - val_accuracy: 0.4116\n",
            "Epoch 5/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2557 - accuracy: 0.3903 - val_loss: 1.2321 - val_accuracy: 0.4095\n",
            "Epoch 6/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2473 - accuracy: 0.3953 - val_loss: 1.2255 - val_accuracy: 0.4206\n",
            "Epoch 7/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2367 - accuracy: 0.4059 - val_loss: 1.2234 - val_accuracy: 0.4185\n",
            "Epoch 8/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2314 - accuracy: 0.4076 - val_loss: 1.2166 - val_accuracy: 0.4240\n",
            "Epoch 9/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2271 - accuracy: 0.4133 - val_loss: 1.2230 - val_accuracy: 0.4163\n",
            "Epoch 10/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2185 - accuracy: 0.4193 - val_loss: 1.2148 - val_accuracy: 0.4226\n",
            "Epoch 11/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2169 - accuracy: 0.4193 - val_loss: 1.2115 - val_accuracy: 0.4294\n",
            "Epoch 12/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.2103 - accuracy: 0.4253 - val_loss: 1.2069 - val_accuracy: 0.4295\n",
            "Epoch 13/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2064 - accuracy: 0.4239 - val_loss: 1.2046 - val_accuracy: 0.4386\n",
            "Epoch 14/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.2056 - accuracy: 0.4275 - val_loss: 1.2042 - val_accuracy: 0.4370\n",
            "Epoch 15/20\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 1.1965 - accuracy: 0.4347 - val_loss: 1.2012 - val_accuracy: 0.4288\n",
            "Epoch 16/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.1952 - accuracy: 0.4383 - val_loss: 1.1985 - val_accuracy: 0.4324\n",
            "Epoch 17/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.1912 - accuracy: 0.4383 - val_loss: 1.1978 - val_accuracy: 0.4340\n",
            "Epoch 18/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.1889 - accuracy: 0.4390 - val_loss: 1.1980 - val_accuracy: 0.4300\n",
            "Epoch 19/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.1846 - accuracy: 0.4465 - val_loss: 1.1954 - val_accuracy: 0.4350\n",
            "Epoch 20/20\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 1.1757 - accuracy: 0.4497 - val_loss: 1.1961 - val_accuracy: 0.4365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edNXMPxwATkx",
        "outputId": "d5d6440f-38be-4456-b5c3-6d67eed9f66c"
      },
      "source": [
        "# Load data\n",
        "with open(blog_posts_data_dir + test_file_name) as r:\n",
        "    test_set = json.load(r)\n",
        "\n",
        "test_posts = [instance[\"post\"] for instance in test_set]\n",
        "test_sequences = tk.texts_to_sequences(test_posts)\n",
        "test_post_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = int(median_words_per_tokenized_sample),\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(test_set):\n",
        "    instance[\"post\"] = test_post_data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))\n",
        "\n",
        "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
        "ages_test = np.array([instance[\"age\"] for instance in test_set])\n",
        "\n",
        "print(model.evaluate(posts_test, ages_test))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model2.predict(posts_test)\n",
        "print(classification_report(np.argmax(ages_test, axis=1), np.argmax(pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263/263 [==============================] - 1s 3ms/step - loss: 1.9699 - accuracy: 0.4421\n",
            "[1.9698514938354492, 0.44209274649620056]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.60      0.53      2698\n",
            "           1       0.44      0.28      0.34      2647\n",
            "           2       0.38      0.52      0.44      2309\n",
            "           3       0.37      0.05      0.09       756\n",
            "\n",
            "    accuracy                           0.43      8410\n",
            "   macro avg       0.42      0.36      0.35      8410\n",
            "weighted avg       0.43      0.43      0.40      8410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lstkls1Z_h0L"
      },
      "source": [
        "##Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xijPmg_R3UTg",
        "outputId": "067cd931-7799-4bac-988f-69c6cafb87b9"
      },
      "source": [
        "def build_model(conv_layers = 2, \n",
        "                dilation_rates = [0, 2, 4, 8, 16], \n",
        "                embed_size = 256):\n",
        "    inp = Input(shape=(None, ))\n",
        "    x = Embedding(input_dim = len(tk.word_counts)+1, \n",
        "                  output_dim = embed_size)(inp)\n",
        "    prefilt_x = Dropout(0.25)(x)\n",
        "    out_conv = []\n",
        "    # dilation rate lets us use ngrams and skip grams to process \n",
        "    for dilation_rate in dilation_rates:\n",
        "        x = prefilt_x\n",
        "        for i in range(2):\n",
        "            if dilation_rate>0:\n",
        "                x = Conv1D(16*2**(i), \n",
        "                           kernel_size = 3, \n",
        "                           dilation_rate = dilation_rate,\n",
        "                          activation = 'relu',\n",
        "                          name = 'ngram_{}_cnn_{}'.format(dilation_rate, i)\n",
        "                          )(x)\n",
        "            else:\n",
        "                x = Conv1D(16*2**(i), \n",
        "                           kernel_size = 1,\n",
        "                          activation = 'relu',\n",
        "                          name = 'word_fcl_{}'.format(i))(x)\n",
        "        out_conv += [Dropout(0.5)(GlobalMaxPool1D()(x))]\n",
        "    x = concatenate(out_conv, axis = -1)    \n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model3 = build_model(dilation_rates = [0, 2, 4, 8])\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, None, 256)    144384      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, None, 256)    0           embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "word_fcl_0 (Conv1D)             (None, None, 16)     4112        dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_2_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_4_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_8_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "word_fcl_1 (Conv1D)             (None, None, 32)     544         word_fcl_0[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "ngram_2_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_2_cnn_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "ngram_4_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_4_cnn_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "ngram_8_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_8_cnn_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_34 (Global (None, 32)           0           word_fcl_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_35 (Global (None, 32)           0           ngram_2_cnn_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_36 (Global (None, 32)           0           ngram_4_cnn_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_37 (Global (None, 32)           0           ngram_8_cnn_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 32)           0           global_max_pooling1d_34[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 32)           0           global_max_pooling1d_35[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 32)           0           global_max_pooling1d_36[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 32)           0           global_max_pooling1d_37[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 128)          0           dropout_63[0][0]                 \n",
            "                                                                 dropout_64[0][0]                 \n",
            "                                                                 dropout_65[0][0]                 \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 64)           8256        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 64)           0           dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 32)           2080        dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 32)           0           dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 1)            33          dropout_68[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 201,025\n",
            "Trainable params: 201,025\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV_mAPkt_xq5"
      },
      "source": [
        "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
        "genders_train = np.array([instance[\"gender\"] for instance in training_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DStuDem0_373",
        "outputId": "e004c398-af2e-4dbc-a4c6-55f6031b10fa"
      },
      "source": [
        "history_1 = model3.fit(posts_train, genders_train, epochs = 10, batch_size = 500, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "54/54 [==============================] - 5s 62ms/step - loss: 0.6428 - accuracy: 0.6625 - val_loss: 0.6156 - val_accuracy: 0.6806\n",
            "Epoch 2/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.6092 - accuracy: 0.6875 - val_loss: 0.6030 - val_accuracy: 0.6806\n",
            "Epoch 3/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.6033 - accuracy: 0.6826 - val_loss: 0.5968 - val_accuracy: 0.6806\n",
            "Epoch 4/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.5952 - accuracy: 0.6808 - val_loss: 0.5913 - val_accuracy: 0.6806\n",
            "Epoch 5/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.5882 - accuracy: 0.6858 - val_loss: 0.5913 - val_accuracy: 0.6821\n",
            "Epoch 6/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.5888 - accuracy: 0.6830 - val_loss: 0.5834 - val_accuracy: 0.6949\n",
            "Epoch 7/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.5818 - accuracy: 0.6903 - val_loss: 0.5801 - val_accuracy: 0.6901\n",
            "Epoch 8/10\n",
            "54/54 [==============================] - 3s 56ms/step - loss: 0.5733 - accuracy: 0.6949 - val_loss: 0.5746 - val_accuracy: 0.6992\n",
            "Epoch 9/10\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.5694 - accuracy: 0.7058 - val_loss: 0.5734 - val_accuracy: 0.7041\n",
            "Epoch 10/10\n",
            "54/54 [==============================] - 3s 56ms/step - loss: 0.5601 - accuracy: 0.7075 - val_loss: 0.5687 - val_accuracy: 0.7078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1qxfLDB_621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35586c30-b4f1-4cec-de0e-d081647a3054"
      },
      "source": [
        "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
        "genders_test = np.array([instance[\"gender\"] for instance in test_set])\n",
        "print(model3.evaluate(posts_test, genders_test))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model3.predict(posts_test)\n",
        "print(classification_report(genders_test, (pred > 0.5).astype(int)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263/263 [==============================] - 1s 3ms/step - loss: 0.5591 - accuracy: 0.7190\n",
            "[0.5591228604316711, 0.7190249562263489]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.16      0.26      2565\n",
            "           1       0.72      0.96      0.83      5845\n",
            "\n",
            "    accuracy                           0.72      8410\n",
            "   macro avg       0.69      0.56      0.54      8410\n",
            "weighted avg       0.70      0.72      0.65      8410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF324WgDBxH9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}