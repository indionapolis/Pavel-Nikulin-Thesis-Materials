{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMRuuEgEhS7D"
      },
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "# import keras\n",
        "# from keras.layers import *\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHOzTC20h4cC",
        "outputId": "9ea9c58c-7102-4425-d147-01c4247d22c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbzvboYPh49v",
        "outputId": "1baa8a13-28c4-4820-9c69-e924a9c51ceb"
      },
      "source": [
        "blog_posts_data_dir = \"/content/drive/MyDrive/datasets/\"\n",
        "# blog_posts_data_dir = \"/content/drive/MyDrive/datasets/BT-AP-19 Corpus/all/\"\n",
        "train_file_name = \"train.json\"\n",
        "test_file_name = \"test.json\"\n",
        "\n",
        "# Load data\n",
        "with open(blog_posts_data_dir + train_file_name) as r:\n",
        "    training_set = json.load(r)\n",
        "training_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': '16', 'gender': 'female', 'post': 'ooh shiny new commenting!'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCt9kOoVjw0t",
        "outputId": "e952da1f-14a0-4f84-caf1-e7a4d3a5c517"
      },
      "source": [
        "raw_posts = [instance[\"post\"] for instance in training_set]\n",
        "len(raw_posts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "526812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbY4Jvzj2sK"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "EXAMINE = 21\n",
        "SEED = 22\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHKiJEW2j0YY"
      },
      "source": [
        "def get_gender_as_num(gender):\n",
        "    if gender == \"male\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnXy_zX_jz-R"
      },
      "source": [
        "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
        "    age = int(age)\n",
        "    if age == 18:\n",
        "        # 13 - 17\n",
        "        return [1, 0, 0, 0]\n",
        "    elif age == 25:\n",
        "        # 23 - 27\n",
        "        return [0, 1, 0, 0]\n",
        "    elif age == 35:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 1, 0]\n",
        "    elif age == 50:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 0, 1]\n",
        "    else:\n",
        "        return [0, 0, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXtup5HfqhBc"
      },
      "source": [
        "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
        "    if age < 18:\n",
        "        # 13 - 17\n",
        "        return [1, 0, 0]\n",
        "    elif age < 28:\n",
        "        # 23 - 27\n",
        "        return [0, 1, 0]\n",
        "    elif age < 49:\n",
        "        # 33 - 48\n",
        "        return [0, 0, 1]\n",
        "    else:\n",
        "        return [0, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuO9UAzajqAb"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 300  # Only consider the first 2\n",
        "\n",
        "median_words_per_sample = maxlen\n",
        "median_words_per_tokenized_sample = maxlen\n",
        "\n",
        "# Map each word to a unique int value\n",
        "MAX_WORD_COUNT = 20000\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words = MAX_WORD_COUNT)\n",
        "posts = [instance[\"post\"] for instance in training_set]\n",
        "tokenizer.fit_on_texts(posts)\n",
        "word_index = dict(list(tokenizer.word_index.items())[:20000])\n",
        "sequences = tokenizer.texts_to_sequences(posts)\n",
        "# median_words_per_tokenized_sample = np.median([len(post) for post in sequences])\n",
        "data = keras.preprocessing.sequence.pad_sequences(sequences, maxlen = maxlen,\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(training_set):\n",
        "    instance[\"post\"] = data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fZ0wuXWkJrh"
      },
      "source": [
        "## Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSwYe9PUiV8l"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TTyXE-LjcFf"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "\n",
        "    inputs = layers.Input(shape=(maxlen,))\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZRD6YcTjo8z"
      },
      "source": [
        "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
        "ages_train = np.array([instance[\"age\"] for instance in training_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMkyfNlNkGzK",
        "outputId": "2ab99b57-ed7a-4d2f-8d31-9be8eb0e68d6"
      },
      "source": [
        "history = model.fit(\n",
        "    posts_train, ages_train, batch_size=500, epochs=4, validation_split = 0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "843/843 [==============================] - 41s 39ms/step - loss: 0.9084 - accuracy: 0.5657 - val_loss: 0.7341 - val_accuracy: 0.6662\n",
            "Epoch 2/4\n",
            "843/843 [==============================] - 24s 29ms/step - loss: 0.7074 - accuracy: 0.6833 - val_loss: 0.7139 - val_accuracy: 0.6766\n",
            "Epoch 3/4\n",
            "843/843 [==============================] - 24s 29ms/step - loss: 0.6776 - accuracy: 0.6982 - val_loss: 0.7124 - val_accuracy: 0.6760\n",
            "Epoch 4/4\n",
            "843/843 [==============================] - 25s 29ms/step - loss: 0.6579 - accuracy: 0.7060 - val_loss: 0.7127 - val_accuracy: 0.6770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzEqJm_3lZ6z"
      },
      "source": [
        "# Load data\n",
        "with open(blog_posts_data_dir + test_file_name) as r:\n",
        "    test_set = json.load(r)\n",
        "\n",
        "test_posts = [instance[\"post\"] for instance in test_set]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_posts)\n",
        "test_post_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = int(median_words_per_tokenized_sample),\n",
        "                                                     padding = \"post\")\n",
        "for i, instance in enumerate(test_set):\n",
        "    instance[\"post\"] = test_post_data[i]\n",
        "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
        "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))\n",
        "\n",
        "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
        "ages_test = np.array([instance[\"age\"] for instance in test_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOL924wSlyhL",
        "outputId": "ea0f2064-5a6f-411d-8198-5e6b3be8ec86"
      },
      "source": [
        "model.evaluate(posts_test, ages_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4116/4116 [==============================] - 68s 16ms/step - loss: 0.7106 - accuracy: 0.6798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7105690836906433, 0.6798326373100281]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA5xVu0fl14J",
        "outputId": "eff0d863-9ba1-40c6-dd28-66de3f3a0b09"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(posts_test)\n",
        "print(classification_report(np.argmax(ages_test, axis=1), np.argmax(pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.66      0.72     44411\n",
            "           1       0.64      0.82      0.72     62574\n",
            "           2       0.60      0.36      0.45     24718\n",
            "\n",
            "    accuracy                           0.68    131703\n",
            "   macro avg       0.68      0.61      0.63    131703\n",
            "weighted avg       0.69      0.68      0.67    131703\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qF8KXg7kMeN"
      },
      "source": [
        "##Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXjC6y4XkN_q"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "\n",
        "    inputs = layers.Input(shape=(maxlen,))\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "\n",
        "    model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model2.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7GdWPYwmAKP"
      },
      "source": [
        "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
        "genders_train = np.array([instance[\"gender\"] for instance in training_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsXOBw5AmAb4",
        "outputId": "161513bb-ccae-4d1c-e081-fd7603299203"
      },
      "source": [
        "history = model2.fit(\n",
        "    posts_train, genders_train, batch_size=500, epochs=4, validation_split = 0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "843/843 [==============================] - 42s 40ms/step - loss: 0.6386 - accuracy: 0.6190 - val_loss: 0.5753 - val_accuracy: 0.6901\n",
            "Epoch 2/4\n",
            "843/843 [==============================] - 23s 28ms/step - loss: 0.5541 - accuracy: 0.7088 - val_loss: 0.5666 - val_accuracy: 0.6942\n",
            "Epoch 3/4\n",
            "843/843 [==============================] - 24s 29ms/step - loss: 0.5393 - accuracy: 0.7184 - val_loss: 0.5674 - val_accuracy: 0.6967\n",
            "Epoch 4/4\n",
            "843/843 [==============================] - 24s 29ms/step - loss: 0.5275 - accuracy: 0.7229 - val_loss: 0.5683 - val_accuracy: 0.6946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En-cxuPwmMtA"
      },
      "source": [
        "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
        "genders_test = np.array([instance[\"gender\"] for instance in test_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPlgjgJKmNIC",
        "outputId": "b2a4168a-95d2-4a1d-8d51-0600483e83a9"
      },
      "source": [
        "model2.evaluate(posts_test, genders_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4116/4116 [==============================] - 69s 17ms/step - loss: 0.5695 - accuracy: 0.6951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5694702863693237, 0.6951170563697815]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6IX-3vImSLx",
        "outputId": "e1f84453-7ed4-4431-a564-664b1ea959fc"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model2.predict(posts_test)\n",
        "print(classification_report(genders_test, (pred > 0.5).astype(int)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70     67312\n",
            "           1       0.69      0.69      0.69     64391\n",
            "\n",
            "    accuracy                           0.70    131703\n",
            "   macro avg       0.69      0.69      0.69    131703\n",
            "weighted avg       0.70      0.70      0.70    131703\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}