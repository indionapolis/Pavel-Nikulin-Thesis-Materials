{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMINE = 21\n",
    "SEED = 22\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_as_num(gender):\n",
    "    if gender == \"male\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
    "    if age < 18:\n",
    "        # 13 - 17\n",
    "        return [1, 0, 0]\n",
    "    elif age < 28:\n",
    "        # 23 - 27\n",
    "        return [0, 1, 0]\n",
    "    elif age < 49:\n",
    "        # 33 - 48\n",
    "        return [0, 0, 1]\n",
    "    else:\n",
    "        return [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
    "    age = int(age)\n",
    "    if age == 18:\n",
    "        # 13 - 17\n",
    "        return [1, 0, 0, 0]\n",
    "    elif age == 25:\n",
    "        # 23 - 27\n",
    "        return [0, 1, 0, 0]\n",
    "    elif age == 35:\n",
    "        # 33 - 48\n",
    "        return [0, 0, 1, 0]\n",
    "    elif age == 50:\n",
    "        # 33 - 48\n",
    "        return [0, 0, 0, 1]\n",
    "    else:\n",
    "        return [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': 'Umar Murtaza: Head of SM Operation', 'age': '50', 'gender': 'female'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_posts_data_dir = \"../Datasets/blog-posts-labeled-with-age-and-gender/\"\n",
    "blog_posts_data_dir = \"../Datasets/BT-AP-19 Corpus/JSON/all/\"\n",
    "train_file_name = \"train.json\"\n",
    "test_file_name = \"test.json\"\n",
    "\n",
    "# Load data\n",
    "with open(blog_posts_data_dir + train_file_name) as r:\n",
    "    training_set = json.load(r)\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33637"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_posts = [instance[\"post\"] for instance in training_set]\n",
    "len(raw_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33637it [00:01, 22211.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# TODO add stop word filtering \n",
    "median_words_per_sample = np.median([len(instance[\"post\"]) for instance in training_set])\n",
    "\n",
    "# Map each word to a unique int value\n",
    "MAX_WORD_COUNT = 20000\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words = MAX_WORD_COUNT)\n",
    "posts = [instance[\"post\"] for instance in training_set]\n",
    "tokenizer.fit_on_texts(posts)\n",
    "word_index = dict(list(tokenizer.word_index.items())[:20000])\n",
    "sequences = tokenizer.texts_to_sequences(posts)\n",
    "median_words_per_tokenized_sample = np.median([len(post) for post in sequences])\n",
    "data = keras.preprocessing.sequence.pad_sequences(sequences, maxlen = int(median_words_per_tokenized_sample)+30,\n",
    "                                                     padding = \"post\")\n",
    "for i, instance in tqdm(enumerate(training_set)):\n",
    "    instance[\"post\"] = data[i]\n",
    "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
    "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][\"post\"].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a6b512e62e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msamples_per_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "samples_count = len(training_set)\n",
    "\n",
    "categories_count = len(training_set[0][\"age\"])\n",
    "\n",
    "samples_per_class = {0 : 0, 1 : 0, 2 : 0}\n",
    "for instance in training_set:\n",
    "    for i, a in enumerate(instance[\"age\"]):\n",
    "        if a == 1:\n",
    "            samples_per_class[i] += 1\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 33637\n",
      "Number of Categories: 4\n",
      "Samples per Class: {0: 0, 1: 0, 2: 0}\n",
      "Median Words per Sample: 55.0\n",
      "Median Words per Tokenized Sample: 9.0\n",
      "Samples to Words Per Sample Ratio: 3737.4444444444443\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Samples:\", samples_count)\n",
    "print(\"Number of Categories:\", categories_count)\n",
    "print(\"Samples per Class:\", samples_per_class)\n",
    "print(\"Median Words per Sample:\", median_words_per_sample)\n",
    "print(\"Median Words per Tokenized Sample:\", median_words_per_tokenized_sample)\n",
    "print(\"Samples to Words Per Sample Ratio:\", samples_count / median_words_per_tokenized_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(instance) for instance in raw_posts])\n",
    "plt.xlabel(\"Length of a Sample\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "\n",
    "glove_path = \"../Models/\"\n",
    "glove_dict = {}\n",
    "with open(glove_path + \"glove.6B.50d.txt\") as f:\n",
    "    for line in f:\n",
    "        line_values = line.split(\" \")\n",
    "        word = line_values[0]\n",
    "        embedding_coefficients = np.asarray(line_values[1 : ], dtype = \"float32\")\n",
    "        glove_dict[word] = embedding_coefficients\n",
    "\n",
    "glove_weights = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    glove_vector = glove_dict.get(word)\n",
    "    if glove_vector is not None:\n",
    "        glove_weights[i] = glove_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_weights.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_words_per_tokenized_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Embedding, Conv, Pool, Conv, Pool, Flatten, Dense, Dense\n",
    "model_1 = keras.Sequential()\n",
    "model_1.add(keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [glove_weights],\n",
    "                                    input_length = int(median_words_per_tokenized_sample)+30, trainable = True))\n",
    "model_1.add(keras.layers.SeparableConv1D(128, 3, activation = \"relu\"))\n",
    "model_1.add(keras.layers.MaxPooling1D())\n",
    "model_1.add(keras.layers.SeparableConv1D(128, 3, activation = \"relu\"))\n",
    "model_1.add(keras.layers.MaxPooling1D())\n",
    "model_1.add(keras.layers.SeparableConv1D(128, 3, activation = \"relu\"))\n",
    "model_1.add(keras.layers.MaxPooling1D())\n",
    "model_1.add(keras.layers.Flatten())\n",
    "model_1.add(keras.layers.Dense(24, activation = \"sigmoid\"))\n",
    "model_1.add(keras.layers.Dense(4, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 39, 50)            1000050   \n",
      "_________________________________________________________________\n",
      "separable_conv1d_18 (Separab (None, 37, 128)           6678      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_19 (Separab (None, 16, 128)           16896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_20 (Separab (None, 6, 128)            16896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                9240      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 100       \n",
      "=================================================================\n",
      "Total params: 1,049,860\n",
      "Trainable params: 1,049,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model_1.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
    "ages_train = np.array([instance[\"age\"] for instance in training_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 1.4170 - acc: 0.3164 - val_loss: 1.3025 - val_acc: 0.3112\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 1.3039 - acc: 0.3384 - val_loss: 1.2717 - val_acc: 0.3789\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 1.2727 - acc: 0.3700 - val_loss: 1.2266 - val_acc: 0.4144\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 1.2266 - acc: 0.4115 - val_loss: 1.1982 - val_acc: 0.4313\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 1.1744 - acc: 0.4449 - val_loss: 1.1722 - val_acc: 0.4478\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 1.1236 - acc: 0.4808 - val_loss: 1.1678 - val_acc: 0.4512\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 1.0723 - acc: 0.5187 - val_loss: 1.1528 - val_acc: 0.4680\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 1.0146 - acc: 0.5551 - val_loss: 1.1681 - val_acc: 0.4740\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 0.9462 - acc: 0.5953 - val_loss: 1.1766 - val_acc: 0.4837\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.8963 - acc: 0.6282 - val_loss: 1.1964 - val_acc: 0.4865\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(posts_train, ages_train, epochs = 10, batch_size = 500, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "# A integer input for vocab indices.\n",
    "inputs = keras.Input(shape=int(median_words_per_tokenized_sample)+30, dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(len(word_index) + 1, EMBEDDING_DIM)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(4, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 39)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 39, 50)            1000050   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 39, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 11, 128)           44928     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2, 128)            114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,176,822\n",
      "Trainable params: 1,176,822\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_3.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "model_3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33637, 39)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 3s 38ms/step - loss: 1.3309 - accuracy: 0.3082 - val_loss: 1.2730 - val_accuracy: 0.3743\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 1.2615 - accuracy: 0.3843 - val_loss: 1.1591 - val_accuracy: 0.4570\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 1.1110 - accuracy: 0.4828 - val_loss: 1.1189 - val_accuracy: 0.4886\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.9852 - accuracy: 0.5588 - val_loss: 1.1429 - val_accuracy: 0.4899\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.8685 - accuracy: 0.6195 - val_loss: 1.1458 - val_accuracy: 0.5128\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.7517 - accuracy: 0.6790 - val_loss: 1.2054 - val_accuracy: 0.5122\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.6492 - accuracy: 0.7243 - val_loss: 1.2589 - val_accuracy: 0.5186\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.5618 - accuracy: 0.7641 - val_loss: 1.3207 - val_accuracy: 0.5251\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 0.4939 - accuracy: 0.7925 - val_loss: 1.3769 - val_accuracy: 0.5303\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.4576 - accuracy: 0.8080 - val_loss: 1.4581 - val_accuracy: 0.5320\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(posts_train, ages_train, epochs = 10, batch_size = 500, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(blog_posts_data_dir + test_file_name) as r:\n",
    "    test_set = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts = [instance[\"post\"] for instance in test_set]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_posts)\n",
    "test_post_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = int(median_words_per_tokenized_sample)+30,\n",
    "                                                     padding = \"post\")\n",
    "for i, instance in enumerate(test_set):\n",
    "    instance[\"post\"] = test_post_data[i]\n",
    "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
    "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
    "ages_test = np.array([instance[\"age\"] for instance in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 0s 2ms/step - loss: 1.2177 - acc: 0.4750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2177083492279053, 0.47502973675727844]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(posts_test, ages_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 0s 1ms/step - loss: 1.4348 - accuracy: 0.5190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4348442554473877, 0.5190249681472778]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(posts_test, ages_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save('../Models/CNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_3.predict(posts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.66      0.61      2698\n",
      "           1       0.47      0.53      0.50      2647\n",
      "           2       0.55      0.38      0.45      2309\n",
      "           3       0.43      0.39      0.41       756\n",
      "\n",
      "    accuracy                           0.52      8410\n",
      "   macro avg       0.50      0.49      0.49      8410\n",
      "weighted avg       0.52      0.52      0.51      8410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model_3.predict(posts_test)\n",
    "print(classification_report(np.argmax(ages_test, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Embedding, Conv, Pool, Conv, Pool, Flatten, Dense, Dense\n",
    "model_2 = keras.Sequential()\n",
    "model_2.add(keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [glove_weights],\n",
    "                                    input_length = int(median_words_per_tokenized_sample)+30, trainable = True))\n",
    "model_2.add(keras.layers.SeparableConv1D(50, 5, activation = \"relu\"))\n",
    "model_2.add(keras.layers.MaxPooling1D())\n",
    "model_2.add(keras.layers.SeparableConv1D(100, 3, activation = \"relu\"))\n",
    "model_2.add(keras.layers.MaxPooling1D())\n",
    "model_2.add(keras.layers.Flatten())\n",
    "model_2.add(keras.layers.Dense(10, activation = \"sigmoid\"))\n",
    "model_2.add(keras.layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
    "genders_train = np.array([instance[\"gender\"] for instance in training_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 39, 50)            1000050   \n",
      "_________________________________________________________________\n",
      "separable_conv1d_23 (Separab (None, 35, 50)            2800      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 17, 50)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_24 (Separab (None, 15, 100)           5250      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 7, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                7010      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,015,121\n",
      "Trainable params: 1,015,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"acc\"])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.6556 - acc: 0.6782 - val_loss: 0.6206 - val_acc: 0.6806\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.6126 - acc: 0.6867 - val_loss: 0.6085 - val_acc: 0.6806\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.5960 - acc: 0.6858 - val_loss: 0.5742 - val_acc: 0.7057\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.5484 - acc: 0.7210 - val_loss: 0.5548 - val_acc: 0.7174\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 2s 28ms/step - loss: 0.5165 - acc: 0.7503 - val_loss: 0.5410 - val_acc: 0.7316\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.4836 - acc: 0.7735 - val_loss: 0.5295 - val_acc: 0.7424\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.4339 - acc: 0.8050 - val_loss: 0.5201 - val_acc: 0.7504\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.3865 - acc: 0.8369 - val_loss: 0.5222 - val_acc: 0.7559\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.3442 - acc: 0.8610 - val_loss: 0.5267 - val_acc: 0.7570\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.3063 - acc: 0.8811 - val_loss: 0.5359 - val_acc: 0.7580\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(posts_train, genders_train, epochs = 10, batch_size = 500, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
    "genders_test = np.array([instance[\"gender\"] for instance in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 0s 1ms/step - loss: 0.5308 - acc: 0.7669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5307836532592773, 0.7669441103935242]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(posts_test, genders_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_2.predict(posts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.51      0.57      2565\n",
      "           1       0.80      0.88      0.84      5845\n",
      "\n",
      "    accuracy                           0.77      8410\n",
      "   macro avg       0.73      0.70      0.71      8410\n",
      "weighted avg       0.76      0.77      0.76      8410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(genders_test, (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
